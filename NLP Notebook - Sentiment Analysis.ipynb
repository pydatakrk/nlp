{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bcf3010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm\n",
    "# import spacy\n",
    "# spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eab81be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext.legacy import datasets, data\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f549101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Containers for tokenisation\n",
    "# using tokenize=\"spacy\" because it's the best.\n",
    "text_field = data.Field(tokenize=\"spacy\", tokenizer_language=\"en_core_web_sm\")\n",
    "label_field = data.LabelField(dtype=torch.float) # torch.float because GPUs use floats\n",
    "\n",
    "# Load dataset and split to train and test data\n",
    "# IMDB dataset (about movies)\n",
    "train, test = datasets.IMDB.splits(text_field=text_field, label_field=label_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc7770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to train and validation set - 80% to train_set, 20% to validation_set\n",
    "# The original set is 25k descriptions(?) so train_set after the split is 20k and valid_set is 5k.\n",
    "train_set, valid_set = train.split(0.8)\n",
    "len(train_set), len(valid_set)  # 20_000, 5_000\n",
    "text_field.build_vocab(train_set, max_size=25_000)\n",
    "label_field.build_vocab(train_set)\n",
    "\n",
    "assert len(text_field.vocab) == 25_002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d2abd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map int to string and string to int\n",
    "# text_field.vocab.itos[186] -> 'though'\n",
    "# text_field.vocab.stoi['though'] -> 186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cc86523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_field.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "089e9316",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(max(train_set, key=lambda x: len(x.text)).text)\n",
    "\n",
    "# but we can do better!\n",
    "train_buckets, valid_buckets, test_buckets = data.BucketIterator.splits(\n",
    "    (train_set, valid_set, test), batch_size=64, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35a768f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class NLPModule(nn.Module):\n",
    "    def __init__(self, num_embedding, embedding_dim, hidden_size, out_features):\n",
    "        # before parent\n",
    "        super().__init__()\n",
    "        # after parent\n",
    "        # warstwa osadzeń/osadzanie(?) embedding\n",
    "        # wektory w przestrzeni znaczeniowej słów\n",
    "        self.embedding = nn.Embedding(num_embedding, embedding_dim)\n",
    "\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, 1)\n",
    "        self.linear = nn.Linear(hidden_size, out_features)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embed_output = self.embedding(input)\n",
    "        rnn_output, hidden_output = self.rnn(embed_output)\n",
    "        # hidden_output is the same as rnn_output[-1]\n",
    "        lin_output = self.linear(hidden_output)\n",
    "\n",
    "        return lin_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "45972d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_embedding = len(text_field.vocab)\n",
    "embedding_dim = 100\n",
    "hidden_size = 256\n",
    "out_features = 1\n",
    "\n",
    "# num_embedding, embedding_dim, hidden_size, out_features\n",
    "\n",
    "model = NLPModule(num_embedding, embedding_dim, hidden_size, out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a3c6bc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2592105"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def policz(mod):\n",
    "    return sum(p.numel() for p in mod.parameters())\n",
    "\n",
    "\n",
    "policz(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3fe5b41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic gradient descent SGD\n",
    "# minimalizować funkcję kosztu (szukanie minimum)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimiser = optim.SGD(module.parameters(), lr=1e-3)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8058738f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciretrion = criterion.to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "def binary_accuracy(prediction, target):\n",
    "    prediction = F.sigmoid(prediction)\n",
    "    prediction = torch.round(prediction)\n",
    "    \n",
    "    compared = (prediction == target).float()\n",
    "    return torch.mean(compared)\n",
    "\n",
    "\n",
    "T = torch.tensor\n",
    "binary_accuracy(T([0, 0.5, .2, 0.001, 0.8]), T([0, 1, 1, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "21dc8651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6925106644630432 0.6925106644630432 0.515625 0.515625\n",
      "0.6913136541843414 0.6901166439056396 0.5546875 0.59375\n",
      "0.692987302939097 0.6963346004486084 0.5208333333333334 0.453125\n",
      "0.6937338262796402 0.6959733963012695 0.52734375 0.546875\n",
      "0.6938868165016174 0.6944987773895264 0.521875 0.5\n",
      "0.6937883794307709 0.6932961940765381 0.5182291666666666 0.5\n",
      "0.6934229561260769 0.6912304162979126 0.5245535714285714 0.5625\n",
      "0.6934435442090034 0.6935876607894897 0.525390625 0.53125\n",
      "0.6932776901457045 0.6919508576393127 0.5260416666666666 0.53125\n",
      "0.6932907223701477 0.6934080123901367 0.5203125 0.46875\n",
      "0.6932447986169294 0.6927855610847473 0.5198863636363636 0.515625\n",
      "0.6928315808375677 0.6882861852645874 0.5260416666666666 0.59375\n",
      "0.6927297252875108 0.6915074586868286 0.5300480769230769 0.578125\n",
      "0.6927759732518878 0.6933771967887878 0.53125 0.546875\n",
      "0.6926431099573771 0.6907830238342285 0.53125 0.53125\n",
      "0.6927378997206688 0.694159746170044 0.52734375 0.46875\n",
      "0.6928126671734978 0.6940089464187622 0.5266544117647058 0.515625\n",
      "0.6924246019787259 0.6858274936676025 0.5347222222222222 0.671875\n",
      "0.6926105838072928 0.6959582567214966 0.5345394736842105 0.53125\n",
      "0.6925784885883332 0.6919686794281006 0.534375 0.53125\n",
      "0.6927099852334886 0.6953399181365967 0.53125 0.46875\n",
      "0.6927937540141019 0.6945528984069824 0.5298295454545454 0.5\n",
      "0.6928092655928239 0.693150520324707 0.5285326086956522 0.5\n",
      "0.6929991642634074 0.6973668336868286 0.5240885416666666 0.421875\n",
      "0.6933654284477234 0.7021557688713074 0.515625 0.3125\n",
      "0.6932959258556366 0.6915583610534668 0.5168269230769231 0.546875\n",
      "0.6932581309919004 0.6922754645347595 0.5167824074074074 0.515625\n",
      "0.6933014690876007 0.6944715976715088 0.5161830357142857 0.5\n",
      "0.6931933041276603 0.6901646852493286 0.5188577586206896 0.59375\n",
      "0.6931995312372844 0.6933801174163818 0.5197916666666667 0.546875\n",
      "0.6933861740173832 0.6989854574203491 0.5161290322580645 0.40625\n",
      "0.6934388000518084 0.695070207118988 0.51416015625 0.453125\n",
      "0.6935146631616534 0.6959422826766968 0.5137310606060606 0.5\n",
      "0.6935301493195927 0.6940411925315857 0.5128676470588235 0.484375\n",
      "0.6935373595782689 0.6937825083732605 0.5125 0.5\n",
      "0.6934715343846215 0.6911676526069641 0.5134548611111112 0.546875\n",
      "0.6935223663175428 0.69535231590271 0.512668918918919 0.484375\n",
      "0.6934921192495447 0.6923729777336121 0.5119243421052632 0.484375\n",
      "0.6933843447611883 0.6892889142036438 0.5144230769230769 0.609375\n",
      "0.6934538498520851 0.6961645483970642 0.5125 0.4375\n",
      "0.6932378891037732 0.6845994591712952 0.5171493902439024 0.703125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "---------------------------------------------------------------------------",
      "KeyboardInterrupt                         Traceback (most recent call last)",
      "<ipython-input-89-87d8c43ed3e3> in <module>\n     18     return ...\n     19     \n---> 20 train(model, train_buckets, optimiser, criterion)\n",
      "<ipython-input-89-87d8c43ed3e3> in train(mod, data, optimiser, criterion)\n     11         losses.append(loss.item())\n     12         metrics.append(metric.item())\n---> 13         loss.backward()\n     14         optimiser.step()\n     15         \n",
      "~/anaconda3/envs/style/lib/python3.8/site-packages/torch/_tensor.py in backward(self, gradient, retain_graph, create_graph, inputs)\n    253                 create_graph=create_graph,\n    254                 inputs=inputs)\n--> 255         torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n    256 \n    257     def register_hook(self, hook):\n",
      "~/anaconda3/envs/style/lib/python3.8/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\n    145         retain_graph = create_graph\n    146 \n--> 147     Variable._execution_engine.run_backward(\n    148         tensors, grad_tensors_, retain_graph, create_graph, inputs,\n    149         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train(mod, data, optimiser, criterion):\n",
    "    losses = []\n",
    "    metrics = []\n",
    "    for bucket in data:\n",
    "        optimiser.zero_grad()\n",
    "        output = mod(bucket.text).squeeze(0).squeeze(1)\n",
    "        loss = criterion(output, bucket.label)\n",
    "        metric = binary_accuracy(output, bucket.label)\n",
    "        losses.append(loss.item())\n",
    "        metrics.append(metric.item())\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        print(np.mean(losses), losses[-1], np.mean(metrics), metrics[-1])\n",
    "        \n",
    "    return ...\n",
    "    \n",
    "train(model, train_buckets, optimiser, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e80feb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6444)\n",
      "tensor(0.5130)\n",
      "tensor(0.4032)\n",
      "tensor(0.3412)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1.]]), tensor([[0.9000]]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Funkcja kosztu, im bliżej 1 (target) tym funkcja kosztu maleje.\n",
    "\n",
    "target = torch.ones([1, 1], dtype=torch.float32)  # 64 classes, batch size = 10\n",
    "input_ = torch.full([1, 1], 0.1)  # A prediction (logit)\n",
    "\n",
    "print(F.binary_cross_entropy_with_logits(input_, target))\n",
    "\n",
    "target = torch.ones([1, 1], dtype=torch.float32)  # 64 classes, batch size = 10\n",
    "input_ = torch.full([1, 1], 0.4)  # A prediction (logit)\n",
    "\n",
    "print(F.binary_cross_entropy_with_logits(input_, target))\n",
    "\n",
    "target = torch.ones([1, 1], dtype=torch.float32)  # 64 classes, batch size = 10\n",
    "input_ = torch.full([1, 1], 0.7)  # A prediction (logit)\n",
    "\n",
    "print(F.binary_cross_entropy_with_logits(input_, target))\n",
    "\n",
    "target = torch.ones([1, 1], dtype=torch.float32)  # 64 classes, batch size = 10\n",
    "input_ = torch.full([1, 1], 0.9)  # A prediction (logit)\n",
    "\n",
    "print(F.binary_cross_entropy_with_logits(input_, target))\n",
    "\n",
    "target, input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfac9f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.8500,  0.2006],\n",
       "          [-0.4605, -0.6672],\n",
       "          [-0.4719, -0.0198]],\n",
       " \n",
       "         [[ 0.6130, -0.8700],\n",
       "          [-0.6430,  0.6836],\n",
       "          [-0.8753, -0.3436]],\n",
       " \n",
       "         [[-0.9134,  0.4095],\n",
       "          [-0.8148, -0.9893],\n",
       "          [ 0.3423,  0.2943]],\n",
       " \n",
       "         [[-0.8185, -0.2287],\n",
       "          [-0.7922, -0.1060],\n",
       "          [-0.7463,  0.4932]],\n",
       " \n",
       "         [[ 0.0135,  0.7411],\n",
       "          [-0.3716, -0.1680],\n",
       "          [-0.7156, -0.5003]]], grad_fn=<StackBackward>),\n",
       " tensor([[[ 0.0135,  0.7411],\n",
       "          [-0.3716, -0.1680],\n",
       "          [-0.7156, -0.5003]]], grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> rnn = nn.RNN(3, 2, 1)\n",
    ">>> input = torch.randn(5, 3, 3)\n",
    ">>> h0 = torch.randn(1, 3, 2)\n",
    ">>> output, hn = rnn(input, h0)\n",
    "output, hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8440222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 9.4736e-01,  7.0916e-01,  4.4942e-01,  3.3067e-01,  2.6436e+00,\n",
       "           4.6544e-01,  2.0053e+00,  8.8530e-01, -1.4538e+00, -1.3253e-01,\n",
       "           3.2943e-01,  3.3413e-01, -2.3301e-01, -1.5218e+00,  3.8434e-01,\n",
       "           9.0579e-01, -2.8931e-01, -8.0191e-02, -1.7367e+00],\n",
       "         [-1.0324e+00, -1.0683e+00,  1.1531e-01, -1.7621e+00, -5.2225e-01,\n",
       "           1.5228e-01, -1.3620e-01,  9.9777e-01, -1.6727e+00, -4.4506e-01,\n",
       "           1.4775e+00, -1.1431e+00, -3.9191e-01, -8.5234e-01,  9.5088e-01,\n",
       "           3.7345e-01,  6.9964e-01,  8.2460e-02, -4.1564e-01],\n",
       "         [ 9.4736e-01,  7.0916e-01,  4.4942e-01,  3.3067e-01,  2.6436e+00,\n",
       "           4.6544e-01,  2.0053e+00,  8.8530e-01, -1.4538e+00, -1.3253e-01,\n",
       "           3.2943e-01,  3.3413e-01, -2.3301e-01, -1.5218e+00,  3.8434e-01,\n",
       "           9.0579e-01, -2.8931e-01, -8.0191e-02, -1.7367e+00],\n",
       "         [ 5.7972e-01, -1.4694e+00,  3.6318e-01,  1.4122e+00, -1.2245e+00,\n",
       "          -4.7360e-01,  3.6868e-01,  1.2903e+00, -1.0298e+00,  7.7494e-01,\n",
       "           7.4428e-01, -3.6535e-01,  8.4345e-01,  3.9994e-02, -2.4258e-01,\n",
       "          -1.5867e-01, -1.2913e+00, -1.3447e+00, -1.0013e+00],\n",
       "         [-9.6589e-01, -6.7295e-01,  9.1192e-02, -2.3341e-01,  8.3923e-01,\n",
       "          -1.0943e+00, -9.5928e-01, -2.7923e-01,  2.3295e+00,  1.7568e+00,\n",
       "           1.4578e-01, -2.5014e-01, -1.7348e+00,  1.2217e+00, -6.7462e-01,\n",
       "          -8.0824e-01,  2.3324e-01,  1.5100e+00,  6.7076e-01],\n",
       "         [ 8.3412e-02,  3.1609e-01,  1.7296e+00,  1.1640e+00, -2.2328e+00,\n",
       "          -1.2598e-03,  4.3732e-01, -4.5461e-01,  4.0579e-01, -2.9410e-01,\n",
       "          -1.3970e-01,  1.6193e+00,  6.4392e-01,  5.4073e-02, -8.6323e-01,\n",
       "          -1.0869e+00,  1.1853e+00, -5.2640e-01, -1.7968e-01],\n",
       "         [-3.1843e-02,  6.6272e-01,  6.5691e-01,  1.7624e+00,  7.5055e-01,\n",
       "           9.5697e-01,  1.0401e-01,  3.9295e-02, -5.6652e-01, -2.2537e+00,\n",
       "           2.8313e+00, -3.5924e-01,  1.6301e+00,  8.3277e-01, -2.5214e-01,\n",
       "           1.3911e+00,  4.6932e-01, -5.3187e-01, -5.3516e-01],\n",
       "         [ 2.5989e-01, -1.1292e+00,  2.1894e-01,  9.7945e-01,  1.8387e+00,\n",
       "          -8.6496e-01,  1.5647e+00, -1.2853e+00,  6.3592e-01, -4.4681e-01,\n",
       "          -1.2091e-01, -4.0581e-01,  3.3273e-02, -1.5045e+00, -7.8658e-01,\n",
       "           1.5822e+00,  2.7383e-03,  3.1287e-01, -1.9182e+00]],\n",
       "\n",
       "        [[-9.6589e-01, -6.7295e-01,  9.1192e-02, -2.3341e-01,  8.3923e-01,\n",
       "          -1.0943e+00, -9.5928e-01, -2.7923e-01,  2.3295e+00,  1.7568e+00,\n",
       "           1.4578e-01, -2.5014e-01, -1.7348e+00,  1.2217e+00, -6.7462e-01,\n",
       "          -8.0824e-01,  2.3324e-01,  1.5100e+00,  6.7076e-01],\n",
       "         [ 8.3412e-02,  3.1609e-01,  1.7296e+00,  1.1640e+00, -2.2328e+00,\n",
       "          -1.2598e-03,  4.3732e-01, -4.5461e-01,  4.0579e-01, -2.9410e-01,\n",
       "          -1.3970e-01,  1.6193e+00,  6.4392e-01,  5.4073e-02, -8.6323e-01,\n",
       "          -1.0869e+00,  1.1853e+00, -5.2640e-01, -1.7968e-01],\n",
       "         [-3.1843e-02,  6.6272e-01,  6.5691e-01,  1.7624e+00,  7.5055e-01,\n",
       "           9.5697e-01,  1.0401e-01,  3.9295e-02, -5.6652e-01, -2.2537e+00,\n",
       "           2.8313e+00, -3.5924e-01,  1.6301e+00,  8.3277e-01, -2.5214e-01,\n",
       "           1.3911e+00,  4.6932e-01, -5.3187e-01, -5.3516e-01],\n",
       "         [ 2.5989e-01, -1.1292e+00,  2.1894e-01,  9.7945e-01,  1.8387e+00,\n",
       "          -8.6496e-01,  1.5647e+00, -1.2853e+00,  6.3592e-01, -4.4681e-01,\n",
       "          -1.2091e-01, -4.0581e-01,  3.3273e-02, -1.5045e+00, -7.8658e-01,\n",
       "           1.5822e+00,  2.7383e-03,  3.1287e-01, -1.9182e+00],\n",
       "         [-9.6589e-01, -6.7295e-01,  9.1192e-02, -2.3341e-01,  8.3923e-01,\n",
       "          -1.0943e+00, -9.5928e-01, -2.7923e-01,  2.3295e+00,  1.7568e+00,\n",
       "           1.4578e-01, -2.5014e-01, -1.7348e+00,  1.2217e+00, -6.7462e-01,\n",
       "          -8.0824e-01,  2.3324e-01,  1.5100e+00,  6.7076e-01],\n",
       "         [ 8.3412e-02,  3.1609e-01,  1.7296e+00,  1.1640e+00, -2.2328e+00,\n",
       "          -1.2598e-03,  4.3732e-01, -4.5461e-01,  4.0579e-01, -2.9410e-01,\n",
       "          -1.3970e-01,  1.6193e+00,  6.4392e-01,  5.4073e-02, -8.6323e-01,\n",
       "          -1.0869e+00,  1.1853e+00, -5.2640e-01, -1.7968e-01],\n",
       "         [-3.1843e-02,  6.6272e-01,  6.5691e-01,  1.7624e+00,  7.5055e-01,\n",
       "           9.5697e-01,  1.0401e-01,  3.9295e-02, -5.6652e-01, -2.2537e+00,\n",
       "           2.8313e+00, -3.5924e-01,  1.6301e+00,  8.3277e-01, -2.5214e-01,\n",
       "           1.3911e+00,  4.6932e-01, -5.3187e-01, -5.3516e-01],\n",
       "         [ 2.5989e-01, -1.1292e+00,  2.1894e-01,  9.7945e-01,  1.8387e+00,\n",
       "          -8.6496e-01,  1.5647e+00, -1.2853e+00,  6.3592e-01, -4.4681e-01,\n",
       "          -1.2091e-01, -4.0581e-01,  3.3273e-02, -1.5045e+00, -7.8658e-01,\n",
       "           1.5822e+00,  2.7383e-03,  3.1287e-01, -1.9182e+00]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> # an Embedding module containing 10 tensors of size 3\n",
    ">>> embedding = nn.Embedding(100, 19)\n",
    ">>> # a batch of 2 samples of 4 indices each\n",
    ">>> input = torch.LongTensor([[1,98,1,0, 4,3,2,9],[4,3,2,9, 4,3,2,9]])\n",
    ">>> embedding(input)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
