{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bcf3010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm\n",
    "# import spacy\n",
    "# spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eab81be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torch\n",
    "import torchtext\n",
    "\n",
    "from torchtext.legacy import datasets, data\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f549101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Containers for tokenisation\n",
    "# using tokenize=\"spacy\" because it's the best.\n",
    "text_field = data.Field(tokenize=\"spacy\", tokenizer_language=\"en_core_web_sm\")\n",
    "label_field = data.LabelField(dtype=torch.float) # torch.float because GPUs use floats\n",
    "\n",
    "# Load dataset and split to train and test data\n",
    "# IMDB dataset (about movies)\n",
    "train, test = datasets.IMDB.splits(text_field=text_field, label_field=label_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc7770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to train and validation set - 80% to train_set, 20% to validation_set\n",
    "# The original set is 25k descriptions(?) so train_set after the split is 20k and valid_set is 5k.\n",
    "train_set, valid_set = train.split(0.8)\n",
    "len(train_set), len(valid_set)  # 20_000, 5_000\n",
    "text_field.build_vocab(train_set, max_size=25_000)\n",
    "label_field.build_vocab(train_set)\n",
    "\n",
    "assert len(text_field.vocab) == 25_002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d2abd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map int to string and string to int\n",
    "# text_field.vocab.itos[186] -> 'though'\n",
    "# text_field.vocab.stoi['though'] -> 186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cc86523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_field.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38604b46",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.22478386e-04, 1.27521614e-03, 1.62283862e-03, 2.01368876e-03,\n",
       "        4.78206052e-03, 4.99459654e-03, 3.71757925e-03, 2.69632565e-03,\n",
       "        2.00288184e-03, 1.78314121e-03, 1.43011527e-03, 1.20136888e-03,\n",
       "        1.01585014e-03, 9.34798271e-04, 7.87103746e-04, 6.30403458e-04,\n",
       "        5.51152738e-04, 5.24135447e-04, 4.50288184e-04, 3.72838617e-04,\n",
       "        3.38616715e-04, 3.09798271e-04, 2.43155620e-04, 2.75576369e-04,\n",
       "        2.07132565e-04, 1.90922190e-04, 1.76512968e-04, 1.27881844e-04,\n",
       "        1.36887608e-04, 1.33285303e-04, 1.13472622e-04, 9.72622478e-05,\n",
       "        7.56484150e-05, 8.64553314e-05, 8.10518732e-05, 4.14265130e-05,\n",
       "        7.92507205e-05, 5.40345821e-05, 6.30403458e-05, 5.76368876e-05,\n",
       "        5.22334294e-05, 5.94380403e-05, 4.50288184e-05, 1.62103746e-05,\n",
       "        1.08069164e-05, 7.20461095e-06, 1.80115274e-06, 1.80115274e-06,\n",
       "        3.60230548e-06, 1.80115274e-06, 1.80115274e-06, 3.60230548e-06,\n",
       "        1.80115274e-06, 0.00000000e+00, 1.80115274e-06, 1.80115274e-06,\n",
       "        0.00000000e+00, 1.80115274e-06, 1.80115274e-06, 0.00000000e+00,\n",
       "        1.80115274e-06, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.80115274e-06, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.80115274e-06, 0.00000000e+00, 3.60230548e-06,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.80115274e-06]),\n",
       " array([  13.  ,   40.76,   68.52,   96.28,  124.04,  151.8 ,  179.56,\n",
       "         207.32,  235.08,  262.84,  290.6 ,  318.36,  346.12,  373.88,\n",
       "         401.64,  429.4 ,  457.16,  484.92,  512.68,  540.44,  568.2 ,\n",
       "         595.96,  623.72,  651.48,  679.24,  707.  ,  734.76,  762.52,\n",
       "         790.28,  818.04,  845.8 ,  873.56,  901.32,  929.08,  956.84,\n",
       "         984.6 , 1012.36, 1040.12, 1067.88, 1095.64, 1123.4 , 1151.16,\n",
       "        1178.92, 1206.68, 1234.44, 1262.2 , 1289.96, 1317.72, 1345.48,\n",
       "        1373.24, 1401.  , 1428.76, 1456.52, 1484.28, 1512.04, 1539.8 ,\n",
       "        1567.56, 1595.32, 1623.08, 1650.84, 1678.6 , 1706.36, 1734.12,\n",
       "        1761.88, 1789.64, 1817.4 , 1845.16, 1872.92, 1900.68, 1928.44,\n",
       "        1956.2 , 1983.96, 2011.72, 2039.48, 2067.24, 2095.  , 2122.76,\n",
       "        2150.52, 2178.28, 2206.04, 2233.8 , 2261.56, 2289.32, 2317.08,\n",
       "        2344.84, 2372.6 , 2400.36, 2428.12, 2455.88, 2483.64, 2511.4 ,\n",
       "        2539.16, 2566.92, 2594.68, 2622.44, 2650.2 , 2677.96, 2705.72,\n",
       "        2733.48, 2761.24, 2789.  ]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "zz = [len(x.text) for x in train_set]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(zz, bins=100, density=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "089e9316",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(max(train_set, key=lambda x: len(x.text)).text)\n",
    "\n",
    "# but we can do better!\n",
    "train_buckets, valid_buckets, test_buckets = data.BucketIterator.splits(\n",
    "    (train_set, valid_set, test), batch_size=64, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "35a768f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class NLPModule(nn.Module):\n",
    "    def __init__(self, num_embedding, embedding_dim, hidden_size, out_features):\n",
    "        # before parent\n",
    "        super().__init__()\n",
    "        # after parent\n",
    "        # warstwa osadzeń/osadzanie(?) embedding\n",
    "        # wektory w przestrzeni znaczeniowej słów\n",
    "        self.embedding = nn.Embedding(num_embedding, embedding_dim)\n",
    "\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, 1)\n",
    "        self.linear = nn.Linear(hidden_size, out_features)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embed_output = self.embedding(input)\n",
    "        rnn_output, hidden_output = self.rnn(embed_output)\n",
    "        # hidden_output is the same as rnn_output[-1]\n",
    "        lin_output = self.linear(hidden_output)\n",
    "\n",
    "        return lin_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dfac9f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.9660, -0.1706],\n",
       "          [ 0.9672, -0.7801],\n",
       "          [-0.2270,  0.8541]],\n",
       " \n",
       "         [[ 0.7891, -0.1707],\n",
       "          [ 0.8006, -0.1496],\n",
       "          [ 0.5672,  0.5370]],\n",
       " \n",
       "         [[-0.2784,  0.3488],\n",
       "          [ 0.9865, -0.7433],\n",
       "          [ 0.4907,  0.2776]],\n",
       " \n",
       "         [[ 0.9574,  0.2454],\n",
       "          [ 0.5468, -0.9582],\n",
       "          [ 0.9314, -0.7436]],\n",
       " \n",
       "         [[ 0.9846, -0.8240],\n",
       "          [ 0.9579, -0.2523],\n",
       "          [ 0.9662, -0.8882]]], grad_fn=<StackBackward>),\n",
       " tensor([[[ 0.9846, -0.8240],\n",
       "          [ 0.9579, -0.2523],\n",
       "          [ 0.9662, -0.8882]]], grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> rnn = nn.RNN(3, 2, 1)\n",
    ">>> input = torch.randn(5, 3, 3)\n",
    ">>> h0 = torch.randn(1, 3, 2)\n",
    ">>> output, hn = rnn(input, h0)\n",
    "output, hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8440222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.6748e+00,  1.3290e+00, -1.0851e+00,  1.7921e-01,  1.3326e+00,\n",
       "           6.6932e-01, -3.6714e-01,  4.0046e-02, -1.7726e+00,  7.2906e-01,\n",
       "          -1.0497e+00, -3.3009e-01, -3.3450e-02, -1.3239e+00,  1.2575e+00,\n",
       "           6.7581e-01, -1.2782e+00,  4.1385e-01, -5.9990e-01],\n",
       "         [-2.1702e-01, -6.4670e-01,  7.9576e-01,  1.0954e-01, -5.5521e-01,\n",
       "           1.0289e+00, -1.5576e+00, -9.4372e-01, -2.4619e-01,  1.2873e+00,\n",
       "           5.0346e-01,  1.8335e+00, -8.6647e-01,  4.6589e-02,  1.4953e-01,\n",
       "           1.1952e+00, -1.0527e-01, -8.9555e-01, -2.4176e-01],\n",
       "         [ 1.6748e+00,  1.3290e+00, -1.0851e+00,  1.7921e-01,  1.3326e+00,\n",
       "           6.6932e-01, -3.6714e-01,  4.0046e-02, -1.7726e+00,  7.2906e-01,\n",
       "          -1.0497e+00, -3.3009e-01, -3.3450e-02, -1.3239e+00,  1.2575e+00,\n",
       "           6.7581e-01, -1.2782e+00,  4.1385e-01, -5.9990e-01],\n",
       "         [ 1.1084e+00,  8.2885e-02,  3.6655e-01, -9.7490e-01, -8.0674e-01,\n",
       "          -1.7280e-01,  1.2545e+00,  1.8969e-03, -1.4910e+00,  9.0939e-02,\n",
       "           1.1761e+00, -5.4066e-01, -1.7968e-01, -1.3320e+00,  7.1545e-02,\n",
       "          -5.5144e-01, -2.7496e-01,  1.0778e+00,  4.6699e-01],\n",
       "         [ 8.7584e-01,  1.5642e+00, -8.4716e-01, -8.8379e-01,  2.7208e-01,\n",
       "           2.2725e-02,  1.1458e-01,  4.6496e-01,  1.7084e+00, -1.8652e+00,\n",
       "           3.3821e-01,  4.1824e-01, -2.8555e-01,  5.5965e-01, -1.8437e+00,\n",
       "          -1.2615e+00,  4.2055e-02, -1.4382e+00,  3.1967e-01],\n",
       "         [ 6.2697e-02,  1.4093e-01,  4.3545e-01, -1.2695e+00,  2.3516e-01,\n",
       "           1.0626e+00,  1.5902e+00,  1.7377e-01,  1.4313e+00,  1.8084e+00,\n",
       "          -1.5630e+00,  1.0178e+00,  3.5872e-01,  1.0550e+00,  1.1793e+00,\n",
       "          -4.8246e-01, -1.1105e+00,  2.2459e-02,  1.1907e+00],\n",
       "         [ 5.6668e-02, -1.6421e-01, -3.5007e+00, -1.1377e+00, -2.1002e-01,\n",
       "           2.2270e-01,  2.7237e-01, -2.2580e+00,  3.0499e-01,  5.4573e-01,\n",
       "           2.5091e+00, -1.4036e+00,  1.1559e-01,  1.7764e+00,  3.0023e-01,\n",
       "           9.2810e-01, -3.4034e-01, -7.2302e-01,  4.5587e-01],\n",
       "         [-5.5606e-01, -8.9345e-01, -7.2802e-01, -3.6973e-02,  3.1958e-01,\n",
       "          -3.5241e-01, -1.4535e+00,  6.3400e-01, -1.3119e-01, -8.0088e-01,\n",
       "           1.0492e+00,  8.9738e-02, -9.5191e-01,  1.7092e+00,  5.5079e-01,\n",
       "          -2.4328e+00, -1.9038e+00, -2.9193e-02,  4.7126e-02]],\n",
       "\n",
       "        [[ 8.7584e-01,  1.5642e+00, -8.4716e-01, -8.8379e-01,  2.7208e-01,\n",
       "           2.2725e-02,  1.1458e-01,  4.6496e-01,  1.7084e+00, -1.8652e+00,\n",
       "           3.3821e-01,  4.1824e-01, -2.8555e-01,  5.5965e-01, -1.8437e+00,\n",
       "          -1.2615e+00,  4.2055e-02, -1.4382e+00,  3.1967e-01],\n",
       "         [ 6.2697e-02,  1.4093e-01,  4.3545e-01, -1.2695e+00,  2.3516e-01,\n",
       "           1.0626e+00,  1.5902e+00,  1.7377e-01,  1.4313e+00,  1.8084e+00,\n",
       "          -1.5630e+00,  1.0178e+00,  3.5872e-01,  1.0550e+00,  1.1793e+00,\n",
       "          -4.8246e-01, -1.1105e+00,  2.2459e-02,  1.1907e+00],\n",
       "         [ 5.6668e-02, -1.6421e-01, -3.5007e+00, -1.1377e+00, -2.1002e-01,\n",
       "           2.2270e-01,  2.7237e-01, -2.2580e+00,  3.0499e-01,  5.4573e-01,\n",
       "           2.5091e+00, -1.4036e+00,  1.1559e-01,  1.7764e+00,  3.0023e-01,\n",
       "           9.2810e-01, -3.4034e-01, -7.2302e-01,  4.5587e-01],\n",
       "         [-5.5606e-01, -8.9345e-01, -7.2802e-01, -3.6973e-02,  3.1958e-01,\n",
       "          -3.5241e-01, -1.4535e+00,  6.3400e-01, -1.3119e-01, -8.0088e-01,\n",
       "           1.0492e+00,  8.9738e-02, -9.5191e-01,  1.7092e+00,  5.5079e-01,\n",
       "          -2.4328e+00, -1.9038e+00, -2.9193e-02,  4.7126e-02],\n",
       "         [ 8.7584e-01,  1.5642e+00, -8.4716e-01, -8.8379e-01,  2.7208e-01,\n",
       "           2.2725e-02,  1.1458e-01,  4.6496e-01,  1.7084e+00, -1.8652e+00,\n",
       "           3.3821e-01,  4.1824e-01, -2.8555e-01,  5.5965e-01, -1.8437e+00,\n",
       "          -1.2615e+00,  4.2055e-02, -1.4382e+00,  3.1967e-01],\n",
       "         [ 6.2697e-02,  1.4093e-01,  4.3545e-01, -1.2695e+00,  2.3516e-01,\n",
       "           1.0626e+00,  1.5902e+00,  1.7377e-01,  1.4313e+00,  1.8084e+00,\n",
       "          -1.5630e+00,  1.0178e+00,  3.5872e-01,  1.0550e+00,  1.1793e+00,\n",
       "          -4.8246e-01, -1.1105e+00,  2.2459e-02,  1.1907e+00],\n",
       "         [ 5.6668e-02, -1.6421e-01, -3.5007e+00, -1.1377e+00, -2.1002e-01,\n",
       "           2.2270e-01,  2.7237e-01, -2.2580e+00,  3.0499e-01,  5.4573e-01,\n",
       "           2.5091e+00, -1.4036e+00,  1.1559e-01,  1.7764e+00,  3.0023e-01,\n",
       "           9.2810e-01, -3.4034e-01, -7.2302e-01,  4.5587e-01],\n",
       "         [-5.5606e-01, -8.9345e-01, -7.2802e-01, -3.6973e-02,  3.1958e-01,\n",
       "          -3.5241e-01, -1.4535e+00,  6.3400e-01, -1.3119e-01, -8.0088e-01,\n",
       "           1.0492e+00,  8.9738e-02, -9.5191e-01,  1.7092e+00,  5.5079e-01,\n",
       "          -2.4328e+00, -1.9038e+00, -2.9193e-02,  4.7126e-02]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> # an Embedding module containing 10 tensors of size 3\n",
    ">>> embedding = nn.Embedding(100, 19)\n",
    ">>> # a batch of 2 samples of 4 indices each\n",
    ">>> input = torch.LongTensor([[1,99,1,0, 4,3,2,9],[4,3,2,9, 4,3,2,9]])\n",
    ">>> embedding(input)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
