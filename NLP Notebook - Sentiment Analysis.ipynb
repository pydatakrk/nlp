{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcf3010",
   "metadata": {
    "id": "2bcf3010"
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm\n",
    "# import spacy\n",
    "# spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eab81be",
   "metadata": {
    "id": "9eab81be"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext.legacy import datasets, data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f549101f",
   "metadata": {
    "id": "f549101f"
   },
   "outputs": [],
   "source": [
    "# Containers for tokenisation\n",
    "# using tokenize=\"spacy\" because it's the best.\n",
    "text_field = data.Field(tokenize=\"spacy\", tokenizer_language=\"en_core_web_sm\", fix_length=100)\n",
    "label_field = data.LabelField(dtype=torch.float) # torch.float because GPUs use floats\n",
    "\n",
    "# Load dataset and split to train and test data\n",
    "# IMDB dataset (about movies)\n",
    "train, test = datasets.IMDB.splits(text_field=text_field, label_field=label_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc7770b",
   "metadata": {
    "id": "8dc7770b"
   },
   "outputs": [],
   "source": [
    "# Split to train and validation set - 80% to train_set, 20% to validation_set\n",
    "# The original set is 25k descriptions(?) so train_set after the split is 20k and valid_set is 5k.\n",
    "train_set, valid_set = train.split(0.8)\n",
    "len(train_set), len(valid_set)  # 20_000, 5_000\n",
    "text_field.build_vocab(train_set, max_size=25_000)\n",
    "label_field.build_vocab(train_set)\n",
    "\n",
    "assert len(text_field.vocab) == 25_002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2abd5f",
   "metadata": {
    "id": "2d2abd5f"
   },
   "outputs": [],
   "source": [
    "# Map int to string and string to int\n",
    "# text_field.vocab.itos[186] -> 'though'\n",
    "# text_field.vocab.stoi['though'] -> 186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc86523",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6cc86523",
    "outputId": "18d914d0-0a1e-4da4-b706-0039bfe6dddd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_field.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089e9316",
   "metadata": {
    "id": "089e9316",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(max(train_set, key=lambda x: len(x.text)).text)\n",
    "\n",
    "# but we can do better!\n",
    "train_buckets, valid_buckets, test_buckets = data.BucketIterator.splits(\n",
    "    (train_set, valid_set, test), batch_size=64, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a768f0",
   "metadata": {
    "id": "35a768f0"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class NLPModule(nn.Module):\n",
    "    def __init__(self, num_embedding, embedding_dim, hidden_size, out_features):\n",
    "        # before parent\n",
    "        super().__init__()\n",
    "        # after parent\n",
    "        # warstwa osadzeń/osadzanie(?) embedding\n",
    "        # wektory w przestrzeni znaczeniowej słów\n",
    "        self.embedding = nn.Embedding(num_embedding, embedding_dim)\n",
    "\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, 1)\n",
    "        self.linear = nn.Linear(hidden_size, out_features)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embed_output = self.embedding(input)\n",
    "        rnn_output, hidden_output = self.rnn(embed_output)\n",
    "        # hidden_output is the same as rnn_output[-1]\n",
    "        lin_output = self.linear(hidden_output)\n",
    "\n",
    "        return lin_output\n",
    "\n",
    "\n",
    "class NLPModuleLSTM(nn.Module):\n",
    "    def __init__(self, num_embedding, embedding_dim, hidden_size, out_features):\n",
    "        # before parent\n",
    "        super().__init__()\n",
    "        # after parent\n",
    "        # warstwa osadzeń/osadzanie(?) embedding\n",
    "        # wektory w przestrzeni znaczeniowej słów\n",
    "        self.embedding = nn.Embedding(num_embedding, embedding_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, 2)\n",
    "        self.linear = nn.Linear(hidden_size * 2, out_features)\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, input):\n",
    "        embed_output = self.embedding(input)\n",
    "        lstm_output, (hidden_output1, hidden_output2) = self.lstm(embed_output)\n",
    "        drop_output = self.dropout(\n",
    "            torch.cat((hidden_output1[-2, :, :], hidden_output1[-1, :, :]), dim=1)\n",
    "        )\n",
    "        lin_output = self.linear(drop_output)\n",
    "\n",
    "        return lin_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45972d1f",
   "metadata": {
    "id": "45972d1f"
   },
   "outputs": [],
   "source": [
    "num_embedding = len(text_field.vocab)\n",
    "embedding_dim = 100\n",
    "hidden_size = 256\n",
    "out_features = 1\n",
    "\n",
    "# num_embedding, embedding_dim, hidden_size, out_features\n",
    "\n",
    "model = NLPModuleLSTM(num_embedding, embedding_dim, hidden_size, out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c6bc10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3c6bc10",
    "outputId": "f63742c2-8d02-4000-b5fc-7dbb5e3c55f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3393641"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def policz(mod):\n",
    "    return sum(p.numel() for p in mod.parameters())\n",
    "\n",
    "\n",
    "policz(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe5b41c",
   "metadata": {
    "id": "3fe5b41c"
   },
   "outputs": [],
   "source": [
    "# Stochastic gradient descent SGD\n",
    "# minimalizować funkcję kosztu (szukanie minimum)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimiser = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8058738f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8058738f",
    "outputId": "674d4f22-48e4-4475-d7a8-6e39ac3ddd73"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciretrion = criterion.to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "def binary_accuracy(prediction, target):\n",
    "    prediction = F.sigmoid(prediction)\n",
    "    prediction = torch.round(prediction)\n",
    "\n",
    "    compared = (prediction == target).float()\n",
    "    return torch.mean(compared)\n",
    "\n",
    "\n",
    "T = torch.tensor\n",
    "binary_accuracy(T([0, 0.5, 0.2, 0.001, 0.8]), T([0, 1, 1, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc8651",
   "metadata": {
    "id": "21dc8651"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def train(mod, data, optimiser, criterion):\n",
    "    losses = []\n",
    "    metrics = []\n",
    "\n",
    "    # train pozwala na akumulację błędów, które potem będziemy propagować wstecz\n",
    "    mod.train()\n",
    "\n",
    "    for bucket in tqdm.tqdm(data):\n",
    "        optimiser.zero_grad()\n",
    "        output = mod(bucket.text).squeeze(0).squeeze(1)\n",
    "        loss = criterion(output, bucket.label)\n",
    "        metric = binary_accuracy(output, bucket.label)\n",
    "        losses.append(loss.item())\n",
    "        metrics.append(metric.item())\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        # print(np.mean(losses), losses[-1], np.mean(metrics), metrics[-1])\n",
    "\n",
    "    return losses, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-vHoNh6cYlcW",
   "metadata": {
    "id": "-vHoNh6cYlcW"
   },
   "outputs": [],
   "source": [
    "def validate(mod, data, criterion):\n",
    "    losses = []\n",
    "    metrics = []\n",
    "\n",
    "    # wyłącza akumulacje błędów (z którego korzystaliśmy w train)\n",
    "    mod.eval()\n",
    "\n",
    "    for bucket in tqdm.tqdm(data):\n",
    "        output = mod(bucket.text).squeeze(0).squeeze(1)\n",
    "        loss = criterion(output, bucket.label)\n",
    "        metric = binary_accuracy(output, bucket.label)\n",
    "        losses.append(loss.item())\n",
    "        metrics.append(metric.item())\n",
    "        # print(np.mean(losses), losses[-1], np.mean(metrics), metrics[-1])\n",
    "\n",
    "    return losses, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SDhHPvnNbKnz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SDhHPvnNbKnz",
    "outputId": "49534f35-db09-4d6d-c4ab-0a88fe319bf8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|██████████| 313/313 [00:13<00:00, 23.35it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 63.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train metrics 0.6911423691926292 0.5257088658146964\n",
      "Validation metrics 0.6891818914232375 0.5318433544303798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:13<00:00, 23.59it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 64.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train metrics 0.688609894281759 0.5415834664536742\n",
      "Validation metrics 0.6752656177629398 0.5676424050632911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:13<00:00, 23.50it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 63.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train metrics 0.6135468603894353 0.6642372204472844\n",
      "Validation metrics 0.552335699147816 0.7213212025316456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:13<00:00, 23.37it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 63.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train metrics 0.44968551054549294 0.7985722843450479\n",
      "Validation metrics 0.46891546532323086 0.7903481012658228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:13<00:00, 23.13it/s]\n",
      "100%|██████████| 79/79 [00:01<00:00, 63.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train metrics 0.3437247764283476 0.8597244408945687\n",
      "Validation metrics 0.46293143286735194 0.7964794303797469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "  train_losses, train_metrics = train(model, train_buckets, optimiser, criterion)\n",
    "  validated_losses, validated_metrics = validate(model, valid_buckets, criterion)\n",
    "  \n",
    "  print()\n",
    "  print(\"Train metrics\", np.mean(train_losses), np.mean(train_metrics))\n",
    "  print(\"Validation metrics\", np.mean(validated_losses), np.mean(validated_metrics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hvMObYJGhMCG",
   "metadata": {
    "id": "hvMObYJGhMCG"
   },
   "outputs": [],
   "source": [
    "tokenizer = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2GLNb1xufMqW",
   "metadata": {
    "id": "2GLNb1xufMqW"
   },
   "outputs": [],
   "source": [
    "def sentiment(model, sentence: str) -> bool:\n",
    "    tokens = tokenizer.tokenizer(sentence)\n",
    "    tokenized = [text_field.vocab.stoi[t.text] for t in tokens]\n",
    "    print(\"|\".join(text_field.vocab.itos[t] for t in tokenized))\n",
    "    result = F.sigmoid(model(torch.LongTensor(tokenized).unsqueeze(1).to(device)))\n",
    "    print(result.to(\"cpu\").detach().numpy().ravel(), sentence)\n",
    "\n",
    "\n",
    "# sentiment(model, \"it's bad\")\n",
    "# sentiment(model, \"it's good\")\n",
    "# sentiment(model, \"it's very bad\")\n",
    "# sentiment(model, \"it's very good\")\n",
    "# sentiment(model, \"it's aweful\")\n",
    "# sentiment(model, \"it's awesome\")\n",
    "# sentiment(model, \"it's great\")\n",
    "# sentiment(model, \"i like this film\")\n",
    "# sentiment(model, \"i don't like this film\")\n",
    "# sentiment(model, \"it is the best movie I have ever seen\")\n",
    "# sentiment(model, \"it is the worst movie I have ever seen\")\n",
    "# sentiment(model, \"borat was the great success, i very much liked this movie, best movie ever\")\n",
    "# sentiment(model, \"very boring movie I didn't like it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iwlFk4RDlpPK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iwlFk4RDlpPK",
    "outputId": "9a36c9e8-be74-4a83-e0e9-d95b25ace78d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unk>|Why|do|I|want|to|write|the|<unk>|comment|on|The|Shawshank|Redemption|?|I|am|not|sure|-|almost|everything|that|could|be|possibly|said|about|it|has|been|said|.|But|like|so|many|other|people|who|wrote|comments|,|I|was|and|am|profoundly|moved|by|this|simple|and|eloquent|depiction|of|hope|and|friendship|and|redemption|.|<unk>|The|only|other|movie|I|have|ever|seen|that|effects|me|as|strongly|is|To|Kill|a|<unk>|.|Both|movies|leave|me|feeling|cleaner|for|having|watched|them|.|<unk>\n",
      "[0.2502538] \n",
      "Why do I want to write the 234th comment on The Shawshank Redemption? I am not sure - almost everything that could be possibly said about it has been said. But like so many other people who wrote comments, I was and am profoundly moved by this simple and eloquent depiction of hope and friendship and redemption.\n",
      "\n",
      "The only other movie I have ever seen that effects me as strongly is To Kill a Mockingbird. Both movies leave me feeling cleaner for having watched them.\n",
      "\n",
      "<unk>|This|film|is|nothing|but|one|cliche|after|another|.|Having|seen|many|of|the|100|'s|of|prison|films|made|from|the|early|30|'s|to|the|50|'s|,|I|was|able|to|pull|almost|every|minute|of|<unk>|from|one|of|those|films|.|<unk>|While|it|is|visually|well|made|and|acted|,|the|story|has|every|plot|point|of|the|\"|standard|\"|prison|film|.|They|have|the|evil|warden|,|innocent|main|character|,|friendly|guilty|guy|,|thugs|and|one|good|old|prisoner|.|Do|n't|waste|your|time|on|this|one|.|Rent|or|buy|some|of|the|classic|'s|of|the|prison|genre|<unk>\n",
      "[0.571742] \n",
      "This film is nothing but one cliche after another. Having seen many of the 100's of prison films made from the early 30's to the 50's, I was able to pull almost every minute of Shawcrap from one of those films.\n",
      "\n",
      "While it is visually well made and acted, the story has every plot point of the \"standard\" prison film. They have the evil warden, innocent main character, friendly guilty guy, thugs and one good old prisoner. Don't waste your time on this one. Rent or buy some of the classic's of the prison genre\n",
      "\n",
      "............|.|.|.|.|.|.|..|...|<unk>|<unk>\n",
      "[0.37871832] ............ . . . . . . .. ... … ....................................................................................................\n",
      "<unk>|<unk>|has|written|a|<unk>|on|_|The|<unk>|Powers|_|;|but|I|should|like|to|<unk>|write|a|<unk>|on|them|,|since|their|lavish|use|in|the|form|of|knocking|,|<unk>|hammering|,|and|tumbling|things|about|has|made|the|whole|of|my|life|a|<unk>|daily|torment|.|Certainly|there|are|people|,|<unk>|,|very|many|,|who|will|<unk>|smile|at|this|,|because|they|are|not|sensitive|to|noise|;|it|is|precisely|<unk>|these|people|,|however|,|who|are|not|sensitive|to|argument|,|thought|,|<unk>|poetry|or|art|,|in|short|,|to|any|kind|of|intellectual|impression|:|a|fact|<unk>|to|be|assigned|to|the|coarse|quality|and|strong|texture|of|their|brain|<unk>|tissues|.|<unk>\n",
      "[0.35438293] \n",
      "Kant has written a treatise on _The Vital Powers_; but I should like to\n",
      "write a dirge on them, since their lavish use in the form of knocking,\n",
      "hammering, and tumbling things about has made the whole of my life a\n",
      "daily torment. Certainly there are people, nay, very many, who will\n",
      "smile at this, because they are not sensitive to noise; it is precisely\n",
      "these people, however, who are not sensitive to argument, thought,\n",
      "poetry or art, in short, to any kind of intellectual impression: a fact\n",
      "to be assigned to the coarse quality and strong texture of their brain\n",
      "tissues.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "shawshank = \"\"\"\n",
    "Why do I want to write the 234th comment on The Shawshank Redemption? I am not sure - almost everything that could be possibly said about it has been said. But like so many other people who wrote comments, I was and am profoundly moved by this simple and eloquent depiction of hope and friendship and redemption.\n",
    "\n",
    "The only other movie I have ever seen that effects me as strongly is To Kill a Mockingbird. Both movies leave me feeling cleaner for having watched them.\n",
    "\"\"\"\n",
    "\n",
    "sentiment(model, shawshank)\n",
    "\n",
    "shawshank2 = \"\"\"\n",
    "This film is nothing but one cliche after another. Having seen many of the 100's of prison films made from the early 30's to the 50's, I was able to pull almost every minute of Shawcrap from one of those films.\n",
    "\n",
    "While it is visually well made and acted, the story has every plot point of the \"standard\" prison film. They have the evil warden, innocent main character, friendly guilty guy, thugs and one good old prisoner. Don't waste your time on this one. Rent or buy some of the classic's of the prison genre\n",
    "\"\"\"\n",
    "sentiment(model, shawshank2)\n",
    "\n",
    "reddit = \"\"\"............ . . . . . . .. ... … ....................................................................................................\"\"\"\n",
    "sentiment(model, reddit)\n",
    "\n",
    "\n",
    "schopenhauer = \"\"\"\n",
    "Kant has written a treatise on _The Vital Powers_; but I should like to\n",
    "write a dirge on them, since their lavish use in the form of knocking,\n",
    "hammering, and tumbling things about has made the whole of my life a\n",
    "daily torment. Certainly there are people, nay, very many, who will\n",
    "smile at this, because they are not sensitive to noise; it is precisely\n",
    "these people, however, who are not sensitive to argument, thought,\n",
    "poetry or art, in short, to any kind of intellectual impression: a fact\n",
    "to be assigned to the coarse quality and strong texture of their brain\n",
    "tissues.\n",
    "\"\"\"\n",
    "\n",
    "sentiment(model, schopenhauer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80feb3a",
   "metadata": {
    "id": "e80feb3a"
   },
   "outputs": [],
   "source": [
    "sentiment(model, \"great success\")\n",
    "# Funkcja kosztu, im bliżej 1 (target) tym funkcja kosztu maleje.\n",
    "\n",
    "target = torch.ones([1, 1], dtype=torch.float32)  # 64 classes, batch size = 10\n",
    "input_ = torch.full([1, 1], 0.1)  # A prediction (logit)\n",
    "\n",
    "print(F.binary_cross_entropy_with_logits(input_, target))\n",
    "\n",
    "target = torch.ones([1, 1], dtype=torch.float32)  # 64 classes, batch size = 10\n",
    "input_ = torch.full([1, 1], 0.4)  # A prediction (logit)\n",
    "\n",
    "print(F.binary_cross_entropy_with_logits(input_, target))\n",
    "\n",
    "target = torch.ones([1, 1], dtype=torch.float32)  # 64 classes, batch size = 10\n",
    "input_ = torch.full([1, 1], 0.7)  # A prediction (logit)\n",
    "\n",
    "print(F.binary_cross_entropy_with_logits(input_, target))\n",
    "\n",
    "target = torch.ones([1, 1], dtype=torch.float32)  # 64 classes, batch size = 10\n",
    "input_ = torch.full([1, 1], 0.9)  # A prediction (logit)\n",
    "\n",
    "print(F.binary_cross_entropy_with_logits(input_, target))\n",
    "\n",
    "target, input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Axn_JzP4YkIe",
   "metadata": {
    "id": "Axn_JzP4YkIe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfac9f54",
   "metadata": {
    "id": "dfac9f54"
   },
   "outputs": [],
   "source": [
    ">>> rnn = nn.RNN(3, 2, 1)\n",
    ">>> input = torch.randn(5, 3, 3)\n",
    ">>> h0 = torch.randn(1, 3, 2)\n",
    ">>> output, hn = rnn(input, h0)\n",
    "output, hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8440222",
   "metadata": {
    "id": "b8440222"
   },
   "outputs": [],
   "source": [
    ">>> # an Embedding module containing 10 tensors of size 3\n",
    ">>> embedding = nn.Embedding(100, 19)\n",
    ">>> # a batch of 2 samples of 4 indices each\n",
    ">>> input = torch.LongTensor([[1,98,1,0, 4,3,2,9],[4,3,2,9, 4,3,2,9]])\n",
    ">>> embedding(input)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of NLP Notebook - Sentiment Analysis.ipynb",
   "provenance": []
  },
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
