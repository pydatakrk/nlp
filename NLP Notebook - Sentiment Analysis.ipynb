{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bcf3010",
   "metadata": {
    "id": "2bcf3010"
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm\n",
    "# import spacy\n",
    "# spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eab81be",
   "metadata": {
    "id": "9eab81be"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext.legacy import datasets, data\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f549101f",
   "metadata": {
    "id": "f549101f"
   },
   "outputs": [],
   "source": [
    "# Containers for tokenisation\n",
    "# using tokenize=\"spacy\" because it's the best.\n",
    "text_field = data.Field(tokenize=\"spacy\", tokenizer_language=\"en_core_web_sm\", fix_length=100)\n",
    "label_field = data.LabelField(dtype=torch.float) # torch.float because GPUs use floats\n",
    "\n",
    "# Load dataset and split to train and test data\n",
    "# IMDB dataset (about movies)\n",
    "train, test = datasets.IMDB.splits(text_field=text_field, label_field=label_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dc7770b",
   "metadata": {
    "id": "8dc7770b"
   },
   "outputs": [],
   "source": [
    "# Split to train and validation set - 80% to train_set, 20% to validation_set\n",
    "# The original set is 25k descriptions(?) so train_set after the split is 20k and valid_set is 5k.\n",
    "train_set, valid_set = train.split(0.8)\n",
    "len(train_set), len(valid_set)  # 20_000, 5_000\n",
    "text_field.build_vocab(train_set, max_size=25_000)\n",
    "label_field.build_vocab(train_set)\n",
    "\n",
    "assert len(text_field.vocab) == 25_002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d2abd5f",
   "metadata": {
    "id": "2d2abd5f"
   },
   "outputs": [],
   "source": [
    "# Map int to string and string to int\n",
    "# text_field.vocab.itos[186] -> 'though'\n",
    "# text_field.vocab.stoi['though'] -> 186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cc86523",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6cc86523",
    "outputId": "b0be576e-3d99-4f24-c489-2f35ba9b27f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_field.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "089e9316",
   "metadata": {
    "id": "089e9316",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(max(train_set, key=lambda x: len(x.text)).text)\n",
    "\n",
    "# but we can do better!\n",
    "train_buckets, valid_buckets, test_buckets = data.BucketIterator.splits(\n",
    "    (train_set, valid_set, test), batch_size=64, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35a768f0",
   "metadata": {
    "id": "35a768f0"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class NLPModule(nn.Module):\n",
    "    def __init__(self, num_embedding, embedding_dim, hidden_size, out_features):\n",
    "        # before parent\n",
    "        super().__init__()\n",
    "        # after parent\n",
    "        # warstwa osadzeń/osadzanie(?) embedding\n",
    "        # wektory w przestrzeni znaczeniowej słów\n",
    "        self.embedding = nn.Embedding(num_embedding, embedding_dim)\n",
    "\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, 1)\n",
    "        self.linear = nn.Linear(hidden_size, out_features)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embed_output = self.embedding(input)\n",
    "        rnn_output, hidden_output = self.rnn(embed_output)\n",
    "        # hidden_output is the same as rnn_output[-1]\n",
    "        lin_output = self.linear(hidden_output)\n",
    "\n",
    "        return lin_output\n",
    "\n",
    "\n",
    "class NLPModuleLSTM(nn.Module):\n",
    "    def __init__(self, num_embedding, embedding_dim, hidden_size, out_features):\n",
    "        # before parent\n",
    "        super().__init__()\n",
    "        # after parent\n",
    "        # warstwa osadzeń/osadzanie(?) embedding\n",
    "        # wektory w przestrzeni znaczeniowej słów\n",
    "        self.embedding = nn.Embedding(num_embedding, embedding_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, 2)\n",
    "        self.linear = nn.Linear(hidden_size * 2, out_features)\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, input):\n",
    "        embed_output = self.embedding(input)\n",
    "        lstm_output, (hidden_output1, hidden_output2) = self.lstm(embed_output)\n",
    "        drop_output = self.dropout(torch.cat((hidden_output1[-2, :, :], hidden_output1[-1, :, :]), dim=1))\n",
    "        lin_output = self.linear(drop_output)\n",
    "\n",
    "        return lin_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45972d1f",
   "metadata": {
    "id": "45972d1f"
   },
   "outputs": [],
   "source": [
    "num_embedding = len(text_field.vocab)\n",
    "embedding_dim = 100\n",
    "hidden_size = 256\n",
    "out_features = 1\n",
    "\n",
    "# num_embedding, embedding_dim, hidden_size, out_features\n",
    "\n",
    "model = NLPModuleLSTM(num_embedding, embedding_dim, hidden_size, out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3c6bc10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3c6bc10",
    "outputId": "17d6a84d-b44f-4f2d-f6c3-ed34965779b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3393641"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def policz(mod):\n",
    "    return sum(p.numel() for p in mod.parameters())\n",
    "\n",
    "\n",
    "policz(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fe5b41c",
   "metadata": {
    "id": "3fe5b41c"
   },
   "outputs": [],
   "source": [
    "# Stochastic gradient descent SGD\n",
    "# minimalizować funkcję kosztu (szukanie minimum)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimiser = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8058738f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8058738f",
    "outputId": "7385f447-f3eb-4130-f604-acda1068a901"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciretrion = criterion.to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "def binary_accuracy(prediction, target):\n",
    "    prediction = F.sigmoid(prediction)\n",
    "    prediction = torch.round(prediction)\n",
    "    \n",
    "    compared = (prediction == target).float()\n",
    "    return torch.mean(compared)\n",
    "\n",
    "\n",
    "T = torch.tensor\n",
    "binary_accuracy(T([0, 0.5, .2, 0.001, 0.8]), T([0, 1, 1, 1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21dc8651",
   "metadata": {
    "id": "21dc8651"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "def train(mod, data, optimiser, criterion):\n",
    "    losses = []\n",
    "    metrics = []\n",
    "\n",
    "    # train pozwala na akumulację błędów, które potem będziemy propagować wstecz\n",
    "    mod.train()\n",
    "\n",
    "    for bucket in tqdm.tqdm(data):\n",
    "        optimiser.zero_grad()\n",
    "        output = mod(bucket.text).squeeze(0).squeeze(1)\n",
    "        loss = criterion(output, bucket.label)\n",
    "        metric = binary_accuracy(output, bucket.label)\n",
    "        losses.append(loss.item())\n",
    "        metrics.append(metric.item())\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        # print(np.mean(losses), losses[-1], np.mean(metrics), metrics[-1])\n",
    "\n",
    "    return losses, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "-vHoNh6cYlcW",
   "metadata": {
    "id": "-vHoNh6cYlcW"
   },
   "outputs": [],
   "source": [
    "def validate(mod, data, criterion):\n",
    "    losses = []\n",
    "    metrics = []\n",
    "\n",
    "    # wyłącza akumulacje błędów (z którego korzystaliśmy w train)\n",
    "    mod.eval()\n",
    "\n",
    "    for bucket in tqdm.tqdm(data):\n",
    "        output = mod(bucket.text).squeeze(0).squeeze(1)\n",
    "        loss = criterion(output, bucket.label)\n",
    "        metric = binary_accuracy(output, bucket.label)\n",
    "        losses.append(loss.item())\n",
    "        metrics.append(metric.item())        \n",
    "        # print(np.mean(losses), losses[-1], np.mean(metrics), metrics[-1])\n",
    "\n",
    "    return losses, metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "SDhHPvnNbKnz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SDhHPvnNbKnz",
    "outputId": "c220fb89-90c7-4df1-a4e8-bfb5095bdbd4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|██████████| 313/313 [00:05<00:00, 54.33it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 142.36it/s]\n",
      "  2%|▏         | 5/313 [00:00<00:07, 43.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train metrics 0.6911784246706734 0.5428813897763578\n",
      "Validation metrics 0.693934605091433 0.520371835443038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.92it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 146.50it/s]\n",
      "  1%|▏         | 4/313 [00:00<00:08, 38.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train metrics 0.6942560600396543 0.5196685303514377\n",
      "Validation metrics 0.6885908042328267 0.53125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 54.21it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 142.88it/s]\n",
      "  2%|▏         | 5/313 [00:00<00:07, 42.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train metrics 0.6833530725381626 0.5558107028753994\n",
      "Validation metrics 0.6809024735342099 0.5814873417721519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 53.78it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 146.08it/s]\n",
      "  2%|▏         | 5/313 [00:00<00:06, 44.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train metrics 0.6288763372281108 0.647064696485623\n",
      "Validation metrics 0.6289972387537172 0.6572389240506329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:05<00:00, 53.76it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 143.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train metrics 0.46747046947098386 0.7854932108626198\n",
      "Validation metrics 0.4758951554570017 0.7792721518987342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "  train_losses, train_metrics = train(model, train_buckets, optimiser, criterion)\n",
    "  validated_losses, validated_metrics = validate(model, valid_buckets, criterion)\n",
    "  \n",
    "  print()\n",
    "  print(\"Train metrics\", np.mean(train_losses), np.mean(train_metrics))\n",
    "  print(\"Validation metrics\", np.mean(validated_losses), np.mean(validated_metrics))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e80feb3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e80feb3a",
    "outputId": "20f45c08-db1c-4bfd-a1de-6d7ad3e988d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6444)\n",
      "tensor(0.5130)\n",
      "tensor(0.4032)\n",
      "tensor(0.3412)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1.]]), tensor([[0.9000]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Funkcja kosztu, im bliżej 1 (target) tym funkcja kosztu maleje.\n",
    "\n",
    "target = torch.ones([1, 1], dtype=torch.float32)  # 64 classes, batch size = 10\n",
    "input_ = torch.full([1, 1], 0.1)  # A prediction (logit)\n",
    "\n",
    "print(F.binary_cross_entropy_with_logits(input_, target))\n",
    "\n",
    "target = torch.ones([1, 1], dtype=torch.float32)  # 64 classes, batch size = 10\n",
    "input_ = torch.full([1, 1], 0.4)  # A prediction (logit)\n",
    "\n",
    "print(F.binary_cross_entropy_with_logits(input_, target))\n",
    "\n",
    "target = torch.ones([1, 1], dtype=torch.float32)  # 64 classes, batch size = 10\n",
    "input_ = torch.full([1, 1], 0.7)  # A prediction (logit)\n",
    "\n",
    "print(F.binary_cross_entropy_with_logits(input_, target))\n",
    "\n",
    "target = torch.ones([1, 1], dtype=torch.float32)  # 64 classes, batch size = 10\n",
    "input_ = torch.full([1, 1], 0.9)  # A prediction (logit)\n",
    "\n",
    "print(F.binary_cross_entropy_with_logits(input_, target))\n",
    "\n",
    "target, input_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "Axn_JzP4YkIe",
   "metadata": {
    "id": "Axn_JzP4YkIe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfac9f54",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dfac9f54",
    "outputId": "27f4f4a0-b984-4dfa-b0c4-ca006f882e16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.8282, -0.1208],\n",
       "          [-0.2118,  0.8283],\n",
       "          [ 0.0370,  0.9418]],\n",
       " \n",
       "         [[-0.4396,  0.7438],\n",
       "          [ 0.0233,  0.9387],\n",
       "          [ 0.6401,  0.9846]],\n",
       " \n",
       "         [[-0.4712,  0.8235],\n",
       "          [ 0.3112,  0.9545],\n",
       "          [ 0.8612,  0.9959]],\n",
       " \n",
       "         [[ 0.2969,  0.9496],\n",
       "          [ 0.2175,  0.9487],\n",
       "          [ 0.7593,  0.9900]],\n",
       " \n",
       "         [[ 0.0371,  0.9331],\n",
       "          [ 0.4106,  0.9637],\n",
       "          [-0.0856,  0.9606]]], grad_fn=<StackBackward>),\n",
       " tensor([[[ 0.0371,  0.9331],\n",
       "          [ 0.4106,  0.9637],\n",
       "          [-0.0856,  0.9606]]], grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> rnn = nn.RNN(3, 2, 1)\n",
    ">>> input = torch.randn(5, 3, 3)\n",
    ">>> h0 = torch.randn(1, 3, 2)\n",
    ">>> output, hn = rnn(input, h0)\n",
    "output, hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8440222",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8440222",
    "outputId": "22a64f01-8b5d-4d21-9a5f-2475b7fcc223"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0889,  0.3945, -1.1772, -0.6415, -0.0728, -1.1369,  1.0803,\n",
       "          -0.6445,  0.9511, -0.7240, -0.2653, -0.2707,  0.5510,  1.1052,\n",
       "          -0.1564, -0.4860, -0.6715,  0.5398, -0.6071],\n",
       "         [-0.5348,  0.1082,  2.0761,  1.6011, -0.5353,  1.5460,  1.2302,\n",
       "          -0.3847,  0.5380, -0.5662,  2.0162, -0.2915,  0.6697,  1.4221,\n",
       "           0.0464,  1.0514,  0.0864,  1.3192,  0.7933],\n",
       "         [ 2.0889,  0.3945, -1.1772, -0.6415, -0.0728, -1.1369,  1.0803,\n",
       "          -0.6445,  0.9511, -0.7240, -0.2653, -0.2707,  0.5510,  1.1052,\n",
       "          -0.1564, -0.4860, -0.6715,  0.5398, -0.6071],\n",
       "         [-1.3756,  0.8178, -0.8051, -1.9905, -0.7490,  0.2198,  1.6624,\n",
       "           0.7889, -0.0715, -0.9256, -0.0417,  0.7219, -1.7215, -1.6133,\n",
       "           0.1947,  0.0199,  0.2287,  0.5282,  1.6839],\n",
       "         [ 0.7632, -0.3519,  0.0248, -1.1205,  0.5446, -0.9172, -0.0353,\n",
       "          -2.3555, -0.6074, -1.5454, -1.2395,  0.4797,  1.4636, -0.2845,\n",
       "          -1.0257,  1.8475, -0.1952, -0.8892, -0.8977],\n",
       "         [ 1.3791,  0.4445, -1.1172, -0.9765, -1.2518,  0.2679,  0.9595,\n",
       "          -0.2700, -0.3403,  0.7234,  0.4038,  0.7239, -1.4730,  2.5762,\n",
       "           0.2921, -0.4655, -0.5235, -0.8873, -0.4166],\n",
       "         [ 0.5059, -0.9055, -0.3891, -0.7361, -1.1754,  0.4795, -0.4490,\n",
       "           0.0582,  0.2895,  0.9443,  0.9201,  0.3366,  0.7893,  0.8019,\n",
       "          -1.7645,  0.7433, -0.5673, -0.9114, -0.3801],\n",
       "         [-0.7706,  0.4492,  1.7238, -0.4921, -0.2911, -0.6603,  1.1434,\n",
       "           0.8150, -0.5568, -0.4014, -0.8573,  2.2423,  1.1196,  3.1250,\n",
       "          -1.0491, -0.9700, -0.0987,  1.5925,  0.7898]],\n",
       "\n",
       "        [[ 0.7632, -0.3519,  0.0248, -1.1205,  0.5446, -0.9172, -0.0353,\n",
       "          -2.3555, -0.6074, -1.5454, -1.2395,  0.4797,  1.4636, -0.2845,\n",
       "          -1.0257,  1.8475, -0.1952, -0.8892, -0.8977],\n",
       "         [ 1.3791,  0.4445, -1.1172, -0.9765, -1.2518,  0.2679,  0.9595,\n",
       "          -0.2700, -0.3403,  0.7234,  0.4038,  0.7239, -1.4730,  2.5762,\n",
       "           0.2921, -0.4655, -0.5235, -0.8873, -0.4166],\n",
       "         [ 0.5059, -0.9055, -0.3891, -0.7361, -1.1754,  0.4795, -0.4490,\n",
       "           0.0582,  0.2895,  0.9443,  0.9201,  0.3366,  0.7893,  0.8019,\n",
       "          -1.7645,  0.7433, -0.5673, -0.9114, -0.3801],\n",
       "         [-0.7706,  0.4492,  1.7238, -0.4921, -0.2911, -0.6603,  1.1434,\n",
       "           0.8150, -0.5568, -0.4014, -0.8573,  2.2423,  1.1196,  3.1250,\n",
       "          -1.0491, -0.9700, -0.0987,  1.5925,  0.7898],\n",
       "         [ 0.7632, -0.3519,  0.0248, -1.1205,  0.5446, -0.9172, -0.0353,\n",
       "          -2.3555, -0.6074, -1.5454, -1.2395,  0.4797,  1.4636, -0.2845,\n",
       "          -1.0257,  1.8475, -0.1952, -0.8892, -0.8977],\n",
       "         [ 1.3791,  0.4445, -1.1172, -0.9765, -1.2518,  0.2679,  0.9595,\n",
       "          -0.2700, -0.3403,  0.7234,  0.4038,  0.7239, -1.4730,  2.5762,\n",
       "           0.2921, -0.4655, -0.5235, -0.8873, -0.4166],\n",
       "         [ 0.5059, -0.9055, -0.3891, -0.7361, -1.1754,  0.4795, -0.4490,\n",
       "           0.0582,  0.2895,  0.9443,  0.9201,  0.3366,  0.7893,  0.8019,\n",
       "          -1.7645,  0.7433, -0.5673, -0.9114, -0.3801],\n",
       "         [-0.7706,  0.4492,  1.7238, -0.4921, -0.2911, -0.6603,  1.1434,\n",
       "           0.8150, -0.5568, -0.4014, -0.8573,  2.2423,  1.1196,  3.1250,\n",
       "          -1.0491, -0.9700, -0.0987,  1.5925,  0.7898]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> # an Embedding module containing 10 tensors of size 3\n",
    ">>> embedding = nn.Embedding(100, 19)\n",
    ">>> # a batch of 2 samples of 4 indices each\n",
    ">>> input = torch.LongTensor([[1,98,1,0, 4,3,2,9],[4,3,2,9, 4,3,2,9]])\n",
    ">>> embedding(input)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "NLP Notebook - Sentiment Analysis.ipynb",
   "provenance": []
  },
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
